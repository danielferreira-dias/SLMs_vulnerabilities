\documentclass[10pt,twocolumn]{article}

% ============================================
% PACKAGES
% ============================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage[margin=0.75in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{float}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{titlesec}

% ============================================
% FORMATTING
% ============================================
% Section formatting with Roman numerals
\renewcommand{\thesection}{\Roman{section}}
\titleformat{\section}{\normalfont\large\bfseries\centering}{\thesection.}{1em}{}
\titleformat{\subsection}{\normalfont\normalsize\bfseries}{\thesubsection}{1em}{}

% Reduce spacing
\setlength{\parindent}{1em}
\setlength{\parskip}{0pt}
\setlength{\columnsep}{0.25in}

% Abstract formatting
\renewenvironment{abstract}{%
    \small
    \begin{center}
    \bfseries Abstract
    \end{center}
    \itshape
}{}

% ============================================
% TITLE AND AUTHORS
% ============================================
\title{\LARGE \textbf{Vulnerabilities of Small Language Models: A Systematic Literature Review}}

\author{
    \begin{tabular}[t]{c}
        \textbf{Daniel Dias}\\
        Polytechnic School of Porto\\
        Porto, Portugal\\
        \texttt{1240145@isep.ipp.pt}
    \end{tabular}
}

\date{}

% ============================================
% DOCUMENT
% ============================================
\begin{document}

\maketitle

% ============================================
% ABSTRACT
% ============================================
\begin{abstract}
\textbf{Context:} Small Language Models (SLMs), typically defined as models with fewer than 7 billion parameters, have emerged as efficient alternatives to Large Language Models (LLMs) for deployment in resource-constrained environments such as edge devices, mobile applications, and IoT systems. As their adoption accelerates, understanding their security vulnerabilities becomes critical.

\textbf{Goal:} This systematic literature review aims to identify, categorize, and analyze the security vulnerabilities specific to small language models, examining how these vulnerabilities differ from those observed in larger models and evaluating proposed mitigation strategies.

\textbf{Method:} We conducted a systematic literature review following PRISMA guidelines, searching multiple databases including IEEE Xplore, ACM Digital Library, arXiv, and Semantic Scholar. Studies were selected based on predefined inclusion and exclusion criteria, with quality assessment performed using established protocols.

\textbf{Results:} Our analysis reveals that SLMs exhibit distinct vulnerability profiles compared to their larger counterparts, with particular susceptibility to prompt injection, jailbreaking, and adversarial attacks. The reduced parameter count often limits the implementation of safety mechanisms, creating unique security challenges.

\textbf{Conclusion:} This review provides the first comprehensive taxonomy of SLM-specific vulnerabilities and identifies critical gaps in current research, offering a foundation for future security research in small language models.
\end{abstract}

\vspace{0.5em}
\noindent\textbf{Keywords:} Small Language Models, Security Vulnerabilities, Prompt Injection, Jailbreaking, Adversarial Attacks, Systematic Literature Review

\vspace{1em}

% ============================================
% I. INTRODUCTION
% ============================================
\section{Introduction}

The field of natural language processing has undergone a fundamental transformation with the advent of transformer-based architectures \cite{vaswani2017attention} and the subsequent development of Large Language Models. Systems such as GPT \cite{achiam2024gpt4}, Claude, and Gemini have demonstrated remarkable capabilities in reasoning, code generation, and creative tasks, driven by scaling to hundreds of billions of parameters \cite{brown2020language,zhao2023survey}. These foundation models have reshaped expectations for artificial intelligence and attracted substantial industrial investment \cite{bommasani2021opportunities}. 

Yet a critical countertrend is emerging: the rise of small language models designed for practical deployment and mitigating private data leakage. Small language models, typically defined as transformer-based architectures with around 7-10 billion parameters \cite{lu2024slm_survey, belcak2025slm_agentic}, have emerged as compelling alternatives that address fundamental limitations of their larger counterparts. SLMs require substantially less memory and processing power, enabling deployment on hardware ranging from consumer GPUs to mobile devices and IoT systems, with proportionally reduced operational costs \cite{lu2024slm_survey, tang2025demystifying}. Edge deployment enables real-time inference without network latency, critical for autonomous systems, industrial automation, and responsive interfaces. Privacy-sensitive applications benefit from local inference, eliminating the need to transmit confidential data to cloud services. Models such as Microsoft's Phi-2 \cite{phi2}, TinyLlama \cite{tinyllama}, and Google's Gemma \cite{gemma} have demonstrated that compact architectures can achieve remarkable performance on targeted tasks, challenging assumptions about the necessity of scale. Recent work from NVIDIA researchers argues that small language models represent the future of agentic AI systems, as the specialized and repetitive tasks characteristic of such systems are better suited to smaller, more efficient models \cite{belcak2025slm_agentic}. This perspective reflects a broader recognition that practical considerations of cost, latency, and deployment constraints increasingly favor compact alternatives.

However, the rapid adoption of small language models has outpaced systematic investigation of their security properties, creating significant risks for deploying organizations. Zhang et al. found that nearly half of the 63 SLMs they tested exhibited attack success rates exceeding 40\% against jailbreak attempts, while over one-third failed to resist even straightforward harmful requests \cite{zhang2025slm_jailbreak}. The fundamental challenge lies in the tension between model capacity and security implementation: safety mechanisms that function effectively in models with hundreds of billions of parameters may degrade or fail entirely when compressed into smaller architectures \cite{li2025quantized_jailbreak}. Yi et al. documented how compression techniques commonly used to create deployable SLMs can compromise security robustness, revealing ``submerged threats'' that emerge from efficiency optimizations \cite{yi2025slm_submerged}. Edge deployment introduces additional attack surfaces, as models operating in physically accessible environments face threats ranging from adversarial input injection \cite{wang2022adversarial_nlp_survey} to direct model extraction \cite{carlini2024stealing,yao2024survey_extraction}. The combination of reduced defensive capacity and expanded attack surface creates a security landscape that demands dedicated investigation, distinct from the extensive but LLM-focused security literature \cite{xu2024jailbreak_survey}.

% ============================================
% II. THEORETICAL BACKGROUND
% ============================================
\section{Theoretical Background}

% Placeholder for theoretical background content
This section will provide foundational concepts necessary for understanding small language model vulnerabilities, including definitions, architectural characteristics, and security frameworks.

\subsection{Small Language Models: Definition and Characteristics}

% Content to be added

\subsection{Security Concepts in Language Models}

% Content to be added

\subsection{Attack Taxonomy}

% Content to be added

% ============================================
% III. METHODOLOGY
% ============================================
\section{Methodology}

% Placeholder for methodology content
This section will describe the systematic review methodology following PRISMA guidelines.

\subsection{Search Strategy}

% Content to be added

\subsection{Inclusion and Exclusion Criteria}

% Content to be added

\subsection{Quality Assessment}

% Content to be added

\subsection{Data Extraction and Synthesis}

% Content to be added

% ============================================
% IV. RESULTS
% ============================================
\section{Results}

% Placeholder for results content
This section will present the findings of the systematic review organized by thematic categories.

\subsection{Study Selection}

% Content to be added

\subsection{Vulnerability Categories}

% Content to be added

\subsection{Mitigation Strategies}

% Content to be added

% ============================================
% V. DISCUSSION
% ============================================
\section{Discussion}

% Placeholder for discussion content
This section will interpret the findings and discuss their implications for research and practice.

\subsection{Key Findings}

% Content to be added

\subsection{Implications for Practice}

% Content to be added

\subsection{Limitations}

% Content to be added

% ============================================
% VI. CONCLUSIONS
% ============================================
\section{Conclusions}

% Placeholder for conclusions content
This section will summarize the key contributions and outline future research directions.

% ============================================
% REFERENCES
% ============================================
\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
