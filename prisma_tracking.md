# PRISMA Tracking: Vulnerabilities of Small Language Models

## Summary Statistics

| Stage | Count |
|-------|-------|
| Records identified from databases | 62 |
| Records from other sources | 3 |
| Duplicates removed | TBD |
| Records screened | TBD |
| Records excluded (screening) | TBD |
| Full-text articles assessed | TBD |
| Full-text excluded | TBD |
| **Studies included in review** | **TBD** |

---

## 1. Identification

### Database Searches

| Database | Search Query | Date | Results |
|----------|--------------|------|---------|
| arXiv | "small language model" vulnerability security attack | 2025-01-17 | 2 |
| arXiv | SLM jailbreak prompt injection adversarial attack | 2025-01-17 | 10 |
| arXiv | DistilBERT MobileBERT ALBERT adversarial robustness | 2025-01-17 | 6 |
| arXiv | "small language model" OR "SLM" attack defense security | 2025-01-17 | 7 |
| arXiv | quantized language model adversarial robustness | 2025-01-17 | 1 |
| Web/Semantic Scholar | "small language model" security vulnerability backdoor poisoning | 2025-01-17 | 10 |
| Web/Semantic Scholar | Phi-2 Phi-3 Microsoft security vulnerability jailbreak | 2025-01-17 | 4 |
| Web/Semantic Scholar | TinyLlama Gemma Mistral 7B adversarial attack | 2025-01-17 | 6 |
| Web/Semantic Scholar | membership inference attack language model BERT GPT privacy | 2025-01-17 | 7 |
| Web/Semantic Scholar | model extraction attack stealing language model | 2025-01-17 | 6 |
| Web/Semantic Scholar | survey systematic review LLM vulnerability security | 2025-01-17 | 6 |
| Web/Semantic Scholar | edge deployment small language model security IoT | 2025-01-17 | 4 |
| ACL Anthology | Llama jailbreak vulnerability attack | 2025-01-17 | 3 |
| **TOTAL** | | | **72** |

### Other Sources

| Source | Description | Date | Results |
|--------|-------------|------|---------|
| NVIDIA Research | SLM Agentic AI paper | 2025-01-17 | 1 |
| Microsoft Security Blog | AI jailbreak mitigation | 2025-01-17 | 1 |
| Anthropic Research | Data poisoning study | 2025-01-17 | 1 |

---

## 2. Duplicate Removal

| Comparison | Duplicates Found |
|------------|------------------|
| Cross-database duplicates | ~10 (estimated) |
| Total duplicates removed | TBD (pending full deduplication) |

---

## 3. Screening (Title/Abstract)

### Papers Identified for Screening

#### A. SLM-Specific Vulnerability Papers (High Relevance)

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 1 | Can Small Language Models Reliably Resist Jailbreak Attacks? A Comprehensive Evaluation | arXiv:2503.06519 | 2025 | arXiv | Pending |
| 2 | Beyond the Tip of Efficiency: Uncovering the Submerged Threats of Jailbreak Attacks in Small Language Models | arXiv:2502.19883 | 2025 | arXiv | Pending |
| 3 | Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs | arXiv:2506.17231 | 2025 | arXiv | Pending |
| 4 | Spirit: Patching Speech Language Models against Jailbreak Attacks | arXiv:2505.13541 | 2025 | arXiv | Pending |
| 5 | Toward Cybersecurity-Expert Small Language Models | arXiv:2510.14113 | 2025 | arXiv | Pending |
| 6 | Small Language Models: Survey, Measurements, and Insights | arXiv:2409.15790 | 2024 | arXiv | Pending |
| 7 | Small Language Models are the Future of Agentic AI | arXiv:2506.02153 (NVIDIA) | 2025 | arXiv | Pending |
| 8 | Win-k: Improved Membership Inference Attacks on Small Language Models | arXiv:2508.01268 | 2025 | arXiv | Pending |
| 9 | AttentionDefense: Leveraging System Prompt Attention for Explainable Defense Against Novel Jailbreaks | arXiv:2504.12321 | 2025 | arXiv | Pending |
| 10 | On Jailbreaking Quantized Language Models Through Fault Injection Attacks | arXiv:2507.03236 | 2025 | arXiv | Pending |

#### B. Jailbreak & Prompt Injection Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 11 | Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails | arXiv:2504.11168 | 2025 | arXiv | Pending |
| 12 | Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities | arXiv:2505.04806 | 2025 | arXiv | Pending |
| 13 | The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses | arXiv:2510.09023 | 2025 | arXiv | Pending |
| 14 | Jailbreaking and Mitigation of Vulnerabilities in Large Language Models | arXiv:2410.15236 | 2024 | arXiv | Pending |
| 15 | PromptScreen: Efficient Jailbreak Mitigation Using Semantic Linear Classification | arXiv:2512.19011 | 2025 | arXiv | Pending |
| 16 | Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing | arXiv:2601.10543 | 2026 | arXiv | Pending |
| 17 | Multimodal Prompt Injection Attacks: Risks and Defenses for Modern LLMs | arXiv:2509.05883 | 2025 | arXiv | Pending |
| 18 | A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models | ACL 2024.findings-acl.443 | 2024 | ACL | Pending |
| 19 | Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs | NeurIPS 2024 | 2024 | NeurIPS | Pending |
| 20 | Jailbreak Attacks and Defenses Against Large Language Models: A Survey | arXiv:2407.04295 | 2024 | arXiv | Pending |
| 21 | Jailbreaking Safety-Aligned LLMs with Simple Adaptive Attacks | OpenReview | 2024 | OpenReview | Pending |
| 22 | SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks | ICLR | 2024 | OpenReview | Pending |
| 23 | Robust Prompt Optimization for Defending Language Models | NeurIPS 2024 | 2024 | NeurIPS | Pending |
| 24 | Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses | arXiv:2504.02080 | 2025 | arXiv | Pending |
| 25 | LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges | arXiv:2506.10022 | 2025 | arXiv | Pending |

#### C. Backdoor & Data Poisoning Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 26 | A Survey on Backdoor Threats in Large Language Models: Attacks, Defenses, and Evaluation Methods | sciltp.com/journals/tai | 2025 | Journal | Pending |
| 27 | A Survey of Backdoor Attacks and Defenses on Large Language Models | arXiv:2406.06852 | 2024 | arXiv | Pending |
| 28 | Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples | arXiv:2510.07192 | 2025 | arXiv | Pending |
| 29 | Composite Backdoor Attacks Against Large Language Models | NAACL 2024.findings-naacl.94 | 2024 | ACL | Pending |
| 30 | Medical Large Language Models are vulnerable to data-poisoning attacks | Nature Medicine | 2024 | Nature | Pending |
| 31 | Revisiting Backdoor Attacks on LLMs: A Stealthy and Practical Poisoning Framework | arXiv:2505.17601 | 2025 | arXiv | Pending |
| 32 | Data Stealing Attacks against Large Language Models via Backdooring | MDPI Electronics | 2024 | MDPI | Pending |

#### D. Adversarial Attacks & Robustness Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 33 | Adversarial Evasion Attack Efficiency against Large Language Models | arXiv:2406.08050 | 2024 | arXiv | Pending |
| 34 | Contextual Breach: Assessing the Robustness of Transformer-based QA Models | arXiv:2409.10997 | 2024 | arXiv | Pending |
| 35 | PhishLang: Phishing Detection Framework Using MobileBERT | arXiv:2408.05667 | 2024 | arXiv | Pending |
| 36 | Explainable Transformer-Based Email Phishing Classification with Adversarial Robustness | arXiv:2511.12085 | 2025 | arXiv | Pending |
| 37 | A Survey of Adversarial Defences and Robustness in NLP | arXiv:2203.06414 | 2022 | arXiv | Pending |
| 38 | Bergeron: Combating Adversarial Attacks through a Conscience-Based Alignment Framework | arXiv:2312.00029 | 2023 | arXiv | Pending |
| 39 | Universal Adversarial Triggers for Attacking and Analyzing NLP | ResearchGate | 2019 | ResearchGate | Pending |
| 40 | Is BERT Really Robust? A Strong Baseline for Natural Language Attack | arXiv:1907.11932 | 2019 | arXiv | Pending |
| 41 | Adv-BERT: BERT is not robust on misspellings! | arXiv:2003.04985 | 2020 | arXiv | Pending |
| 42 | DARD: Dice Adversarial Robustness Distillation | arXiv:2509.11525 | 2025 | arXiv | Pending |
| 43 | Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data | arXiv:2505.09974 | 2025 | arXiv | Pending |

#### E. Membership Inference & Privacy Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 44 | Membership Inference Attacks on Large-Scale Models: A Survey | arXiv:2503.19338 | 2025 | arXiv | Pending |
| 45 | Membership Inference Attacks against Language Models via Neighbourhood Comparison | ACL 2023.findings-acl.719 | 2023 | ACL | Pending |
| 46 | Membership Inference Attack Susceptibility of Clinical Language Models | arXiv:2104.08305 | 2021 | arXiv | Pending |
| 47 | Membership Inference Attacks against Large Vision-Language Models | NeurIPS 2024 | 2024 | NeurIPS | Pending |
| 48 | Semantic Membership Inference Attack against Large Language Models | arXiv | 2024 | arXiv | Pending |
| 49 | Membership Inference Attacks Against In-Context Learning | CCS 2024 | 2024 | ACM | Pending |
| 50 | Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment | arXiv:2407.06443 | 2024 | arXiv | Pending |

#### F. Model Extraction & Stealing Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 51 | A Survey on Model Extraction Attacks and Defenses for Large Language Models | arXiv:2506.22521 / KDD 2025 | 2025 | arXiv/ACM | Pending |
| 52 | Stealing Part of a Production Language Model (ICML 2024 Best Paper) | Carlini et al. | 2024 | ICML | Pending |
| 53 | KGDist: A Prompt-Based Distillation Attack against LMs Augmented with Knowledge Graphs | RAID 2024 | 2024 | ACM | Pending |
| 54 | Efficient and Effective Model Extraction | arXiv:2409.14122 | 2024 | arXiv | Pending |
| 55 | Pleak: Prompt leaking attacks against large language model applications | CCS 2024 | 2024 | ACM | Pending |

#### G. Survey Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 56 | When LLMs Meet Cybersecurity: A Systematic Literature Review | Springer Cybersecurity | 2025 | Springer | Pending |
| 57 | Large Language Models in Cybersecurity: A Survey of Applications, Vulnerabilities, and Defense Techniques | MDPI | 2025 | MDPI | Pending |
| 58 | Large Language Models for Cyber Security: A Systematic Literature Review | arXiv:2405.04760 | 2024 | arXiv | Pending |
| 59 | Vulnerability Detection in Large Language Models: Addressing Security Concerns | MDPI | 2024 | MDPI | Pending |
| 60 | Security Concerns for Large Language Models: A Survey | ScienceDirect | 2025 | Elsevier | Pending |
| 61 | A Survey on Collaborating Small and Large Language Models | arXiv:2510.13890 | 2025 | arXiv | Pending |
| 62 | Exploring the Role of Large Language Models in Cybersecurity: A Systematic Survey | arXiv:2504.15622 | 2025 | arXiv | Pending |

#### H. Edge Deployment & Specific Model Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 63 | Deploying AI on Edge: Advancement and Challenges in Edge Intelligence | MDPI Mathematics | 2025 | MDPI | Pending |
| 64 | Intelligent data analysis in edge computing with Large Language Models | Frontiers in Computer Science | 2025 | Frontiers | Pending |
| 65 | Empowering Large Language Models to edge intelligence: A survey | ScienceDirect | 2025 | Elsevier | Pending |
| 66 | LLMs and IoT: A Comprehensive Survey | TechRxiv | 2024 | TechRxiv | Pending |
| 67 | Edge-LLMs: Edge-Device Large Language Model Competition | OpenReview | 2024 | OpenReview | Pending |
| 68 | On the Surprising Efficacy of LLMs for Penetration-Testing | arXiv:2507.00829 | 2025 | arXiv | Pending |

### Excluded at Screening

| # | Title | Reason for Exclusion |
|---|-------|---------------------|
| | (To be completed during screening phase) | |

**Exclusion Reason Categories:**
- Not about SLMs (Small Language Models)
- Not about vulnerabilities/security
- Not peer-reviewed/preprint quality insufficient
- Duplicate
- Not in English
- Full text not available
- Out of scope (e.g., only large models >10B without transferability to SLMs)

---

## 4. Eligibility (Full-Text Assessment)

### Included in Final Review

| # | Citation Key | Title | Authors | Year | Source | DOI |
|---|--------------|-------|---------|------|--------|-----|
| | (To be completed after full-text review) | | | | | |

### Excluded at Full-Text

| # | Citation Key | Title | Reason for Exclusion |
|---|--------------|-------|---------------------|
| | (To be completed after full-text review) | | |

---

## 5. PRISMA Flow Diagram Data

```
Identification:
├── Database records: 62
└── Other sources: 3
    └── Total: 65

Screening:
├── After duplicates removed: ~55 (estimated)
├── To be screened: 68 unique papers identified
└── Excluded: TBD

Eligibility:
├── Full-text to be assessed: TBD
└── Excluded: TBD

Included:
└── Studies in review: TBD
```

---

## Search Strategy

### Inclusion Criteria
- [x] Published between 2020 and 2025
- [x] Focus on Small Language Models (SLMs) defined as models with <10B parameters (per NVIDIA definition)
- [x] Addresses security vulnerabilities, attacks, or adversarial aspects (all types)
- [x] Peer-reviewed or high-quality preprint
- [x] English language

### Exclusion Criteria
- [x] Focuses exclusively on large models (>10B parameters) without applicability to SLMs
- [x] No security/vulnerability component
- [x] Non-English
- [x] Duplicate publication
- [x] Unable to access full text

### Target Databases
1. arXiv (cs.CR, cs.CL, cs.LG)
2. Web of Science
3. Semantic Scholar
4. IEEE Xplore
5. ACM Digital Library

### Search Terms
```
Primary Query:
("small language model" OR "SLM" OR "lightweight language model" OR "edge language model"
OR "compact language model" OR "efficient language model" OR "mobile language model"
OR "Phi-2" OR "Phi-3" OR "Gemma" OR "TinyLlama" OR "MobileBERT" OR "DistilBERT"
OR "MiniLM" OR "ALBERT" OR "Llama 7B" OR "Mistral 7B")
AND
("vulnerability" OR "attack" OR "adversarial" OR "security" OR "jailbreak"
OR "prompt injection" OR "backdoor" OR "poisoning" OR "membership inference"
OR "data extraction" OR "model stealing" OR "evasion" OR "robustness")

Date filter: 2020-01-01 to 2025-12-31
```

---

## Vulnerability Categories Identified

Based on initial screening, papers cover these vulnerability types:

### Attack Types
1. **Jailbreak Attacks** - Bypassing safety alignment (Papers: 1-2, 11-25)
2. **Prompt Injection** - Manipulating model behavior via prompts (Papers: 11-17)
3. **Backdoor Attacks** - Hidden triggers in training (Papers: 26-32)
4. **Data Poisoning** - Corrupting training data (Papers: 26-32)
5. **Adversarial Examples** - Input perturbations (Papers: 33-43)
6. **Membership Inference** - Privacy leakage detection (Papers: 44-50)
7. **Model Extraction** - Stealing model functionality (Papers: 51-55)
8. **Fault Injection** - Hardware-level attacks on quantized models (Paper: 10)

### Model Types Studied
- **Decoder-only SLMs**: Phi-2, Phi-3, Gemma, TinyLlama, Llama-7B, Mistral-7B, Qwen
- **Encoder-only SLMs**: BERT, DistilBERT, MobileBERT, ALBERT, RoBERTa
- **Speech LLMs**: Qwen2-Audio, LLaMa-Omni

---

## Notes

- Last updated: 2025-01-17
- SLM Definition: <10B parameters (NVIDIA, "Small Language Models are the future of Agentic AI", arXiv:2506.02153)
- Vulnerability scope: All types (jailbreaks, prompt injection, backdoors, adversarial attacks, data poisoning, membership inference, model extraction, etc.)
- Review protocol registered at: N/A
- Initial search identified 68 unique papers for screening
- Key finding: 47.6% of SLMs show high susceptibility to jailbreak attacks (ASR > 40%) per arXiv:2503.06519
