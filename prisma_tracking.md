# PRISMA Tracking: Vulnerabilities of Small Language Models

## Summary Statistics

| Stage | Count |
|-------|-------|
| Records identified from databases | 62 |
| Records from other sources | 3 |
| Duplicates removed | TBD |
| Records screened | TBD |
| Records excluded (screening) | TBD |
| Full-text articles assessed | TBD |
| Full-text excluded | TBD |
| **Studies included in review** | **TBD** |

---

## 1. Identification

### Database Searches

| Database | Search Query | Date | Results |
|----------|--------------|------|---------|
| arXiv | "small language model" vulnerability security attack | 2025-01-17 | 2 |
| arXiv | SLM jailbreak prompt injection adversarial attack | 2025-01-17 | 10 |
| arXiv | DistilBERT MobileBERT ALBERT adversarial robustness | 2025-01-17 | 6 |
| arXiv | "small language model" OR "SLM" attack defense security | 2025-01-17 | 7 |
| arXiv | quantized language model adversarial robustness | 2025-01-17 | 1 |
| Web/Semantic Scholar | "small language model" security vulnerability backdoor poisoning | 2025-01-17 | 10 |
| Web/Semantic Scholar | Phi-2 Phi-3 Microsoft security vulnerability jailbreak | 2025-01-17 | 4 |
| Web/Semantic Scholar | TinyLlama Gemma Mistral 7B adversarial attack | 2025-01-17 | 6 |
| Web/Semantic Scholar | membership inference attack language model BERT GPT privacy | 2025-01-17 | 7 |
| Web/Semantic Scholar | model extraction attack stealing language model | 2025-01-17 | 6 |
| Web/Semantic Scholar | survey systematic review LLM vulnerability security | 2025-01-17 | 6 |
| Web/Semantic Scholar | edge deployment small language model security IoT | 2025-01-17 | 4 |
| ACL Anthology | Llama jailbreak vulnerability attack | 2025-01-17 | 3 |
| **TOTAL** | | | **72** |

### Other Sources

| Source | Description | Date | Results |
|--------|-------------|------|---------|
| NVIDIA Research | SLM Agentic AI paper | 2025-01-17 | 1 |
| Microsoft Security Blog | AI jailbreak mitigation | 2025-01-17 | 1 |
| Anthropic Research | Data poisoning study | 2025-01-17 | 1 |

---

## 2. Duplicate Removal

| Comparison | Duplicates Found |
|------------|------------------|
| Cross-database duplicates | ~10 (estimated) |
| Total duplicates removed | TBD (pending full deduplication) |

---

## 3. Screening (Title/Abstract)

### Papers Identified for Screening

#### A. SLM-Specific Vulnerability Papers (High Relevance)

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 1 | Can Small Language Models Reliably Resist Jailbreak Attacks? A Comprehensive Evaluation | arXiv:2503.06519 | 2025 | arXiv | Pending |
| 2 | Beyond the Tip of Efficiency: Uncovering the Submerged Threats of Jailbreak Attacks in Small Language Models | arXiv:2502.19883 | 2025 | arXiv | Pending |
| 3 | Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs | arXiv:2506.17231 | 2025 | arXiv | Pending |
| 4 | Spirit: Patching Speech Language Models against Jailbreak Attacks | arXiv:2505.13541 | 2025 | arXiv | Pending |
| 5 | Toward Cybersecurity-Expert Small Language Models | arXiv:2510.14113 | 2025 | arXiv | Pending |
| 6 | Small Language Models: Survey, Measurements, and Insights | arXiv:2409.15790 | 2024 | arXiv | Pending |
| 7 | Small Language Models are the Future of Agentic AI | arXiv:2506.02153 (NVIDIA) | 2025 | arXiv | Pending |
| 8 | Win-k: Improved Membership Inference Attacks on Small Language Models | arXiv:2508.01268 | 2025 | arXiv | Pending |
| 9 | AttentionDefense: Leveraging System Prompt Attention for Explainable Defense Against Novel Jailbreaks | arXiv:2504.12321 | 2025 | arXiv | Pending |
| 10 | On Jailbreaking Quantized Language Models Through Fault Injection Attacks | arXiv:2507.03236 | 2025 | arXiv | Pending |

#### B. Jailbreak & Prompt Injection Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 11 | Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails | arXiv:2504.11168 | 2025 | arXiv | Pending |
| 12 | Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities | arXiv:2505.04806 | 2025 | arXiv | Pending |
| 13 | The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses | arXiv:2510.09023 | 2025 | arXiv | Pending |
| 14 | Jailbreaking and Mitigation of Vulnerabilities in Large Language Models | arXiv:2410.15236 | 2024 | arXiv | Pending |
| 15 | PromptScreen: Efficient Jailbreak Mitigation Using Semantic Linear Classification | arXiv:2512.19011 | 2025 | arXiv | Pending |
| 16 | Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing | arXiv:2601.10543 | 2026 | arXiv | Pending |
| 17 | Multimodal Prompt Injection Attacks: Risks and Defenses for Modern LLMs | arXiv:2509.05883 | 2025 | arXiv | Pending |
| 18 | A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models | ACL 2024.findings-acl.443 | 2024 | ACL | Pending |
| 19 | Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs | NeurIPS 2024 | 2024 | NeurIPS | Pending |
| 20 | Jailbreak Attacks and Defenses Against Large Language Models: A Survey | arXiv:2407.04295 | 2024 | arXiv | Pending |
| 21 | Jailbreaking Safety-Aligned LLMs with Simple Adaptive Attacks | OpenReview | 2024 | OpenReview | Pending |
| 22 | SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks | ICLR | 2024 | OpenReview | Pending |
| 23 | Robust Prompt Optimization for Defending Language Models | NeurIPS 2024 | 2024 | NeurIPS | Pending |
| 24 | Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses | arXiv:2504.02080 | 2025 | arXiv | Pending |
| 25 | LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges | arXiv:2506.10022 | 2025 | arXiv | Pending |

#### C. Backdoor & Data Poisoning Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 26 | A Survey on Backdoor Threats in Large Language Models: Attacks, Defenses, and Evaluation Methods | sciltp.com/journals/tai | 2025 | Journal | Pending |
| 27 | A Survey of Backdoor Attacks and Defenses on Large Language Models | arXiv:2406.06852 | 2024 | arXiv | Pending |
| 28 | Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples | arXiv:2510.07192 | 2025 | arXiv | Pending |
| 29 | Composite Backdoor Attacks Against Large Language Models | NAACL 2024.findings-naacl.94 | 2024 | ACL | Pending |
| 30 | Medical Large Language Models are vulnerable to data-poisoning attacks | Nature Medicine | 2024 | Nature | Pending |
| 31 | Revisiting Backdoor Attacks on LLMs: A Stealthy and Practical Poisoning Framework | arXiv:2505.17601 | 2025 | arXiv | Pending |
| 32 | Data Stealing Attacks against Large Language Models via Backdooring | MDPI Electronics | 2024 | MDPI | Pending |

#### D. Adversarial Attacks & Robustness Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 33 | Adversarial Evasion Attack Efficiency against Large Language Models | arXiv:2406.08050 | 2024 | arXiv | Pending |
| 34 | Contextual Breach: Assessing the Robustness of Transformer-based QA Models | arXiv:2409.10997 | 2024 | arXiv | Pending |
| 35 | PhishLang: Phishing Detection Framework Using MobileBERT | arXiv:2408.05667 | 2024 | arXiv | Pending |
| 36 | Explainable Transformer-Based Email Phishing Classification with Adversarial Robustness | arXiv:2511.12085 | 2025 | arXiv | Pending |
| 37 | A Survey of Adversarial Defences and Robustness in NLP | arXiv:2203.06414 | 2022 | arXiv | Pending |
| 38 | Bergeron: Combating Adversarial Attacks through a Conscience-Based Alignment Framework | arXiv:2312.00029 | 2023 | arXiv | Pending |
| 39 | Universal Adversarial Triggers for Attacking and Analyzing NLP | ResearchGate | 2019 | ResearchGate | Pending |
| 40 | Is BERT Really Robust? A Strong Baseline for Natural Language Attack | arXiv:1907.11932 | 2019 | arXiv | Pending |
| 41 | Adv-BERT: BERT is not robust on misspellings! | arXiv:2003.04985 | 2020 | arXiv | Pending |
| 42 | DARD: Dice Adversarial Robustness Distillation | arXiv:2509.11525 | 2025 | arXiv | Pending |
| 43 | Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data | arXiv:2505.09974 | 2025 | arXiv | Pending |

#### E. Membership Inference & Privacy Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 44 | Membership Inference Attacks on Large-Scale Models: A Survey | arXiv:2503.19338 | 2025 | arXiv | Pending |
| 45 | Membership Inference Attacks against Language Models via Neighbourhood Comparison | ACL 2023.findings-acl.719 | 2023 | ACL | Pending |
| 46 | Membership Inference Attack Susceptibility of Clinical Language Models | arXiv:2104.08305 | 2021 | arXiv | Pending |
| 47 | Membership Inference Attacks against Large Vision-Language Models | NeurIPS 2024 | 2024 | NeurIPS | Pending |
| 48 | Semantic Membership Inference Attack against Large Language Models | arXiv | 2024 | arXiv | Pending |
| 49 | Membership Inference Attacks Against In-Context Learning | CCS 2024 | 2024 | ACM | Pending |
| 50 | Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment | arXiv:2407.06443 | 2024 | arXiv | Pending |

#### F. Model Extraction & Stealing Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 51 | A Survey on Model Extraction Attacks and Defenses for Large Language Models | arXiv:2506.22521 / KDD 2025 | 2025 | arXiv/ACM | Pending |
| 52 | Stealing Part of a Production Language Model (ICML 2024 Best Paper) | Carlini et al. | 2024 | ICML | Pending |
| 53 | KGDist: A Prompt-Based Distillation Attack against LMs Augmented with Knowledge Graphs | RAID 2024 | 2024 | ACM | Pending |
| 54 | Efficient and Effective Model Extraction | arXiv:2409.14122 | 2024 | arXiv | Pending |
| 55 | Pleak: Prompt leaking attacks against large language model applications | CCS 2024 | 2024 | ACM | Pending |

#### G. Survey Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 56 | When LLMs Meet Cybersecurity: A Systematic Literature Review | Springer Cybersecurity | 2025 | Springer | Pending |
| 57 | Large Language Models in Cybersecurity: A Survey of Applications, Vulnerabilities, and Defense Techniques | MDPI | 2025 | MDPI | Pending |
| 58 | Large Language Models for Cyber Security: A Systematic Literature Review | arXiv:2405.04760 | 2024 | arXiv | Pending |
| 59 | Vulnerability Detection in Large Language Models: Addressing Security Concerns | MDPI | 2024 | MDPI | Pending |
| 60 | Security Concerns for Large Language Models: A Survey | ScienceDirect | 2025 | Elsevier | Pending |
| 61 | A Survey on Collaborating Small and Large Language Models | arXiv:2510.13890 | 2025 | arXiv | Pending |
| 62 | Exploring the Role of Large Language Models in Cybersecurity: A Systematic Survey | arXiv:2504.15622 | 2025 | arXiv | Pending |

#### H. Edge Deployment & Specific Model Papers

| # | Title | Authors/Source | Year | Database | Status |
|---|-------|----------------|------|----------|--------|
| 63 | Deploying AI on Edge: Advancement and Challenges in Edge Intelligence | MDPI Mathematics | 2025 | MDPI | Pending |
| 64 | Intelligent data analysis in edge computing with Large Language Models | Frontiers in Computer Science | 2025 | Frontiers | Pending |
| 65 | Empowering Large Language Models to edge intelligence: A survey | ScienceDirect | 2025 | Elsevier | Pending |
| 66 | LLMs and IoT: A Comprehensive Survey | TechRxiv | 2024 | TechRxiv | Pending |
| 67 | Edge-LLMs: Edge-Device Large Language Model Competition | OpenReview | 2024 | OpenReview | Pending |
| 68 | On the Surprising Efficacy of LLMs for Penetration-Testing | arXiv:2507.00829 | 2025 | arXiv | Pending |

### Excluded at Screening

| # | Title | Reason for Exclusion |
|---|-------|---------------------|
| | (To be completed during screening phase) | |

**Exclusion Reason Categories:**
- Not about SLMs (Small Language Models)
- Not about vulnerabilities/security
- Not peer-reviewed/preprint quality insufficient
- Duplicate
- Not in English
- Full text not available
- Out of scope (e.g., only large models >10B without transferability to SLMs)

---

## 4. Eligibility (Full-Text Assessment)

### Included in Final Review

| # | Citation Key | Title | Authors | Year | Source | DOI |
|---|--------------|-------|---------|------|--------|-----|
| | (To be completed after full-text review) | | | | | |

### Excluded at Full-Text

| # | Citation Key | Title | Reason for Exclusion |
|---|--------------|-------|---------------------|
| | (To be completed after full-text review) | | |

---

## 5. PRISMA Flow Diagram Data

```
Identification:
├── Database records: 62
└── Other sources: 3
    └── Total: 65

Screening:
├── After duplicates removed: ~55 (estimated)
├── To be screened: 68 unique papers identified
└── Excluded: TBD

Eligibility:
├── Full-text to be assessed: TBD
└── Excluded: TBD

Included:
└── Studies in review: TBD
```

---

## Search Strategy

### Inclusion Criteria
- [x] Published between 2020 and 2025
- [x] Focus on Small Language Models (SLMs) defined as models with <10B parameters (per NVIDIA definition)
- [x] Addresses security vulnerabilities, attacks, or adversarial aspects (all types)
- [x] Peer-reviewed or high-quality preprint
- [x] English language

### Exclusion Criteria
- [x] Focuses exclusively on large models (>10B parameters) without applicability to SLMs
- [x] No security/vulnerability component
- [x] Non-English
- [x] Duplicate publication
- [x] Unable to access full text

### Target Databases
1. arXiv (cs.CR, cs.CL, cs.LG)
2. Web of Science
3. Semantic Scholar
4. IEEE Xplore
5. ACM Digital Library

### Search Terms
```
Primary Query:
("small language model" OR "SLM" OR "lightweight language model" OR "edge language model"
OR "compact language model" OR "efficient language model" OR "mobile language model"
OR "Phi-2" OR "Phi-3" OR "Gemma" OR "TinyLlama" OR "MobileBERT" OR "DistilBERT"
OR "MiniLM" OR "ALBERT" OR "Llama 7B" OR "Mistral 7B")
AND
("vulnerability" OR "attack" OR "adversarial" OR "security" OR "jailbreak"
OR "prompt injection" OR "backdoor" OR "poisoning" OR "membership inference"
OR "data extraction" OR "model stealing" OR "evasion" OR "robustness")

Date filter: 2020-01-01 to 2025-12-31
```

---

## Vulnerability Categories Identified

Based on initial screening, papers cover these vulnerability types:

### Attack Types
1. **Jailbreak Attacks** - Bypassing safety alignment (Papers: 1-2, 11-25)
2. **Prompt Injection** - Manipulating model behavior via prompts (Papers: 11-17)
3. **Backdoor Attacks** - Hidden triggers in training (Papers: 26-32)
4. **Data Poisoning** - Corrupting training data (Papers: 26-32)
5. **Adversarial Examples** - Input perturbations (Papers: 33-43)
6. **Membership Inference** - Privacy leakage detection (Papers: 44-50)
7. **Model Extraction** - Stealing model functionality (Papers: 51-55)
8. **Fault Injection** - Hardware-level attacks on quantized models (Paper: 10)

### Model Types Studied
- **Decoder-only SLMs**: Phi-2, Phi-3, Gemma, TinyLlama, Llama-7B, Mistral-7B, Qwen
- **Encoder-only SLMs**: BERT, DistilBERT, MobileBERT, ALBERT, RoBERTa
- **Speech LLMs**: Qwen2-Audio, LLaMa-Omni

---

## Notes

- Last updated: 2025-01-17
- SLM Definition: <10B parameters (NVIDIA, "Small Language Models are the future of Agentic AI", arXiv:2506.02153)
- Vulnerability scope: All types (jailbreaks, prompt injection, backdoors, adversarial attacks, data poisoning, membership inference, model extraction, etc.)
- Review protocol registered at: N/A
- Initial search identified 68 unique papers for screening
- Key finding: 47.6% of SLMs show high susceptibility to jailbreak attacks (ASR > 40%) per arXiv:2503.06519

---

## TITLE/ABSTRACT SCREENING RESULTS (2025-01-17)

### Screening Summary

| Metric | Count |
|--------|-------|
| Total papers screened | 68 |
| **INCLUDED** | 64 |
| **EXCLUDED** | 4 |

---

### Screening Decisions by Category

#### Category A: SLM-Specific Vulnerability Papers (1-10)

| # | Title | Decision | Rationale |
|---|-------|----------|-----------|
| 1 | Can Small Language Models Reliably Resist Jailbreak Attacks? | **INCLUDE** | Directly evaluates 63 SLMs against jailbreak attacks; core paper |
| 2 | Beyond the Tip of Efficiency: Uncovering Submerged Threats of Jailbreak Attacks in SLMs | **INCLUDE** | Compares 13 SLMs (<4B) vs 3 LLMs on security |
| 3 | Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs | **INCLUDE** | Uses BERT, ALBERT, RoBERTa as student SLMs |
| 4 | Spirit: Patching Speech Language Models against Jailbreak Attacks | **INCLUDE** | Studies Qwen2-Audio-7B, LLaMa-Omni vulnerabilities |
| 5 | Toward Cybersecurity-Expert Small Language Models | **INCLUDE** | Uses Qwen3-4B, 8B, 14B for security tasks |
| 6 | Small Language Models: Survey, Measurements, and Insights | **INCLUDE** | Foundational SLM survey (100M-5B parameters) |
| 7 | Small Language Models are the Future of Agentic AI (NVIDIA) | **INCLUDE** | Defines SLMs <10B; discusses deployment considerations |
| 8 | Win-k: Improved Membership Inference Attacks on Small Language Models | **INCLUDE** | Directly about privacy attacks on SLMs |
| 9 | AttentionDefense: Leveraging System Prompt Attention for Defense | **INCLUDE** | Proposes SLM-based defense mechanism |
| 10 | On Jailbreaking Quantized Language Models Through Fault Injection | **INCLUDE** | Studies quantized models (typical for edge SLMs) |

**Category A Result: 10 INCLUDED, 0 EXCLUDED**

---

#### Category B: Jailbreak & Prompt Injection Papers (11-25)

| # | Title | Decision | Rationale |
|---|-------|----------|-----------|
| 11 | Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails | **INCLUDE** | Attack techniques applicable to SLM guardrails |
| 12 | Red Teaming the Mind of the Machine | **INCLUDE** | Tests Mistral 7B, Vicuna (SLMs) |
| 13 | The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses | **INCLUDE** | Evaluates defenses including StruQ, MetaSecAlign |
| 14 | Jailbreaking and Mitigation of Vulnerabilities in LLMs | **INCLUDE** | General methodology applicable to SLMs |
| 15 | PromptScreen: Efficient Jailbreak Mitigation | **INCLUDE** | Lightweight defense suitable for SLMs |
| 16 | Defending LLMs Against Jailbreak via In-Decoding Safety-Awareness | **INCLUDE** | Defense mechanism applicable across model sizes |
| 17 | Multimodal Prompt Injection Attacks | **INCLUDE** | Applicable to multimodal SLMs |
| 18 | A Comprehensive Study of Jailbreak Attack versus Defense | **INCLUDE** | Tests Vicuna, Llama (7B variants) |
| 19 | Bag of Tricks: Benchmarking of Jailbreak Attacks | **INCLUDE** | Tests Llama2-7B, Llama3-8B, Vicuna-13B |
| 20 | Jailbreak Attacks and Defenses Against LLMs: A Survey | **INCLUDE** | Comprehensive survey covering all model sizes |
| 21 | Jailbreaking Safety-Aligned LLMs with Simple Adaptive Attacks | **INCLUDE** | Tests Llama-2-7B/13B, Gemma-7B |
| 22 | SmoothLLM: Defending LLMs Against Jailbreaking Attacks | **INCLUDE** | Defense applicable to SLMs |
| 23 | Robust Prompt Optimization for Defending Language Models | **INCLUDE** | Tests on Llama-2; 0% ASR achieved |
| 24 | Evolving Security in LLMs: Study of Jailbreak Attacks and Defenses | **INCLUDE** | Analyzes Llama 2/3 security evolution |
| 25 | LLMs Caught in the Crossfire: Malware Requests and Jailbreak | **INCLUDE** | Tests models from 350M to 8B |

**Category B Result: 15 INCLUDED, 0 EXCLUDED**

---

#### Category C: Backdoor & Data Poisoning Papers (26-32)

| # | Title | Decision | Rationale |
|---|-------|----------|-----------|
| 26 | A Survey on Backdoor Threats in LLMs | **INCLUDE** | Comprehensive survey applicable to SLMs |
| 27 | A Survey of Backdoor Attacks and Defenses on LLMs | **INCLUDE** | Survey covering attack techniques |
| 28 | Poisoning Attacks on LLMs Require Near-constant Number of Poison Samples | **INCLUDE** | Shows attack scales regardless of model size |
| 29 | Composite Backdoor Attacks Against LLMs | **INCLUDE** | Tests LLaMA-7B; 100% ASR achieved |
| 30 | Medical LLMs are vulnerable to data-poisoning attacks | **INCLUDE** | Nature Medicine; high-impact venue |
| 31 | Revisiting Backdoor Attacks on LLMs: Stealthy and Practical | **INCLUDE** | Practical attack framework |
| 32 | Data Stealing Attacks against LLMs via Backdooring | **INCLUDE** | Backdoor-based extraction attacks |

**Category C Result: 7 INCLUDED, 0 EXCLUDED**

---

#### Category D: Adversarial Attacks & Robustness Papers (33-43)

| # | Title | Decision | Rationale |
|---|-------|----------|-----------|
| 33 | Adversarial Evasion Attack Efficiency against LLMs | **INCLUDE** | Tests BERT, DistilBERT, ALBERT, XLNet |
| 34 | Contextual Breach: Assessing Robustness of Transformer-based QA | **INCLUDE** | Tests DistilBERT, DeBERTa robustness |
| 35 | PhishLang: Phishing Detection Using MobileBERT | **INCLUDE** | Uses MobileBERT; tests adversarial robustness |
| 36 | Explainable Transformer-Based Email Phishing with Adversarial Robustness | **INCLUDE** | Uses DistilBERT with FGM adversarial training |
| 37 | A Survey of Adversarial Defences and Robustness in NLP | **INCLUDE** | Survey mentions DistilBERT for efficient defense |
| 38 | Bergeron: Combating Adversarial Attacks | **INCLUDE** | Uses DistilBERT for safety checking |
| 39 | Universal Adversarial Triggers for Attacking and Analyzing NLP | **EXCLUDE** | Published 2019; outside date range (2020-2025) |
| 40 | Is BERT Really Robust? A Strong Baseline for Natural Language Attack | **EXCLUDE** | Published 2019; outside date range (2020-2025) |
| 41 | Adv-BERT: BERT is not robust on misspellings! | **INCLUDE** | Published 2020; within date range |
| 42 | DARD: Dice Adversarial Robustness Distillation | **INCLUDE** | Distillation for adversarial robustness |
| 43 | Analysing Safety Risks in LLMs Fine-Tuned with Cyber Security Data | **INCLUDE** | Tests Phi 3 Mini 3.8B, Mistral 7B, Llama 3 8B |

**Category D Result: 9 INCLUDED, 2 EXCLUDED**

---

#### Category E: Membership Inference & Privacy Papers (44-50)

| # | Title | Decision | Rationale |
|---|-------|----------|-----------|
| 44 | Membership Inference Attacks on Large-Scale Models: A Survey | **INCLUDE** | First comprehensive MIA survey for LMs |
| 45 | Membership Inference Attacks via Neighbourhood Comparison | **INCLUDE** | 2023 ACL; applicable to SLMs |
| 46 | Membership Inference Attack Susceptibility of Clinical Language Models | **INCLUDE** | Tests BERT, GPT-2; shows smaller models leak less |
| 47 | Membership Inference Attacks against Large Vision-Language Models | **INCLUDE** | Applicable to multimodal SLMs |
| 48 | Semantic Membership Inference Attack against LLMs | **INCLUDE** | Tests BERT, GPT-2, GPT-3 |
| 49 | Membership Inference Attacks Against In-Context Learning | **INCLUDE** | CCS 2024; studies ICL privacy |
| 50 | Exposing Privacy Gaps: MIA on Preference Data for LLM Alignment | **INCLUDE** | Preference data vulnerabilities |

**Category E Result: 7 INCLUDED, 0 EXCLUDED**

---

#### Category F: Model Extraction & Stealing Papers (51-55)

| # | Title | Decision | Rationale |
|---|-------|----------|-----------|
| 51 | A Survey on Model Extraction Attacks and Defenses for LLMs | **INCLUDE** | Comprehensive survey; KDD 2025 |
| 52 | Stealing Part of a Production Language Model | **INCLUDE** | ICML 2024 Best Paper; seminal work |
| 53 | KGDist: Prompt-Based Distillation Attack against KG-augmented LMs | **INCLUDE** | Distillation attack methodology |
| 54 | Efficient and Effective Model Extraction | **INCLUDE** | Extraction attack techniques |
| 55 | Pleak: Prompt leaking attacks against LLM applications | **INCLUDE** | CCS 2024; prompt extraction |

**Category F Result: 5 INCLUDED, 0 EXCLUDED**

---

#### Category G: Survey Papers (56-62)

| # | Title | Decision | Rationale |
|---|-------|----------|-----------|
| 56 | When LLMs Meet Cybersecurity: A Systematic Literature Review | **INCLUDE** | Springer; 300+ works analyzed |
| 57 | LLMs in Cybersecurity: Survey of Vulnerabilities and Defense | **INCLUDE** | MDPI; 223 studies analyzed |
| 58 | LLMs for Cyber Security: A Systematic Literature Review | **INCLUDE** | arXiv; 185 papers from top venues |
| 59 | Vulnerability Detection in LLMs: Addressing Security Concerns | **INCLUDE** | MDPI; vulnerability focus |
| 60 | Security Concerns for LLMs: A Survey | **INCLUDE** | ScienceDirect; covers sleeper agents, deception |
| 61 | A Survey on Collaborating Small and Large Language Models | **INCLUDE** | Directly discusses SLM-LLM collaboration |
| 62 | Exploring the Role of LLMs in Cybersecurity: Systematic Survey | **INCLUDE** | Mentions SLM for defense (KL divergence) |

**Category G Result: 7 INCLUDED, 0 EXCLUDED**

---

#### Category H: Edge Deployment & Specific Model Papers (63-68)

| # | Title | Decision | Rationale |
|---|-------|----------|-----------|
| 63 | Deploying AI on Edge: Advancement and Challenges | **INCLUDE** | Discusses edge security vulnerabilities |
| 64 | Intelligent data analysis in edge computing with LLMs | **INCLUDE** | Edge LLM privacy/security challenges |
| 65 | Empowering LLMs to edge intelligence: A survey | **INCLUDE** | Edge deployment security considerations |
| 66 | LLMs and IoT: A Comprehensive Survey | **INCLUDE** | IoT/edge security vulnerabilities |
| 67 | Edge-LLMs: Edge-Device Large Language Model Competition | **INCLUDE** | Edge deployment challenges |
| 68 | On the Surprising Efficacy of LLMs for Penetration-Testing | **EXCLUDE** | Focus is on USING LLMs for pentesting, not vulnerabilities IN SLMs |

**Category H Result: 5 INCLUDED, 1 EXCLUDED**

---

### Papers Excluded at Screening (Final List)

| # | Title | Year | Reason for Exclusion |
|---|-------|------|---------------------|
| 39 | Universal Adversarial Triggers for Attacking and Analyzing NLP | 2019 | Outside date range (pre-2020) |
| 40 | Is BERT Really Robust? A Strong Baseline for Natural Language Attack | 2019 | Outside date range (pre-2020) |
| 68 | On the Surprising Efficacy of LLMs for Penetration-Testing | 2025 | Out of scope: focuses on using LLMs for security tasks, not vulnerabilities in SLMs |

Note: Paper #16 (arXiv:2601.10543) has year "2026" which appears to be a typo in the arXiv ID. Will verify during full-text review.

---

### Screening Statistics Summary

| Category | Screened | Included | Excluded |
|----------|----------|----------|----------|
| A. SLM-Specific | 10 | 10 | 0 |
| B. Jailbreak/Prompt Injection | 15 | 15 | 0 |
| C. Backdoor/Poisoning | 7 | 7 | 0 |
| D. Adversarial/Robustness | 11 | 9 | 2 |
| E. Membership Inference | 7 | 7 | 0 |
| F. Model Extraction | 5 | 5 | 0 |
| G. Surveys | 7 | 7 | 0 |
| H. Edge Deployment | 6 | 5 | 1 |
| **TOTAL** | **68** | **65** | **3** |

---

### Papers Proceeding to Full-Text Review: 65

Next step: Full-text eligibility assessment to confirm:
1. Full text is accessible
2. Paper specifically addresses or is applicable to SLMs (<10B parameters)
3. Contains empirical results or systematic analysis on vulnerabilities
4. Meets quality standards for inclusion in systematic review
